{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Initialization**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3roIer--jJmP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "N5Kp40wePVaI"
      },
      "outputs": [],
      "source": [
        "REPEAT_TIME = 4 # Number of times to augment the data (how many times?)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "wTL9z0eOykG9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0lRSfnpynFo",
        "outputId": "7caa8010-60b5-42df-e5e6-3f0fc0f7828f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LkrRthosQlYZ"
      },
      "outputs": [],
      "source": [
        "from itertools import chain\n",
        "from nltk.corpus import wordnet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Functions**"
      ],
      "metadata": {
        "id": "m4Eex09wjcoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_synonym(text, sth_keep):\n",
        "    th_text, th_word = 1, 1 # Minimum acceptable length for text and word\n",
        "    arr_synonym = []\n",
        "    dict_synonym = {}\n",
        "\n",
        "    split_text = text.split(' ')\n",
        "\n",
        "    if len(split_text) > th_text:\n",
        "\n",
        "        sth_keep_str = ''\n",
        "        for i in range(len(sth_keep)):\n",
        "            sth_keep_str += sth_keep[i]\n",
        "            if i <= len(sth_keep)-2:\n",
        "                sth_keep_str += ' '\n",
        "\n",
        "        sth_keep_split = sth_keep_str.split(' ')\n",
        "\n",
        "        for i in range(len(split_text)):\n",
        "            word = split_text[i]\n",
        "\n",
        "            if not(word in sth_keep_split):\n",
        "                if len(word) > th_word:\n",
        "                    synonyms = wordnet.synsets(word)\n",
        "                    lemmas = set(chain.from_iterable([word.lemma_names() for word in synonyms]))\n",
        "                    if len(lemmas) > 0:\n",
        "                        dict_synonym[str(i)] = []\n",
        "                        for item in lemmas:\n",
        "                            if not(item in dict_synonym[str(i)]):\n",
        "                                if item != word and item.find('_') == -1 and len(item) > th_word and not(item.isupper()): #and len(item) == len(word):\n",
        "                                    dict_synonym[str(i)].append(item)\n",
        "\n",
        "        for rp in range(REPEAT_TIME):\n",
        "            temp_text = split_text.copy()\n",
        "            for i in range(len(split_text)):\n",
        "                if str(i) in dict_synonym.keys():\n",
        "                    if rp < len(dict_synonym[str(i)]):\n",
        "                        temp_text[i] = (dict_synonym[str(i)])[rp]\n",
        "\n",
        "            if temp_text != split_text:\n",
        "                temp_arr = ' '.join(temp_text)\n",
        "                if not(temp_arr in arr_synonym):\n",
        "                    arr_synonym.append(temp_arr)\n",
        "\n",
        "    return arr_synonym"
      ],
      "metadata": {
        "id": "uhbpO242-Wf9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Add Synonym(s)**"
      ],
      "metadata": {
        "id": "I23TXZZKkYPt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tzHqWSmnxeYH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "702df666-2bea-40dc-b1fe-9fa7b7d3d70e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:  A proposal for an early quota system will be at the center of this report.\n",
            "Parts of text that should be kept:  ['early quota system']\n",
            "Results:  ['A proposition for an early quota system leave represent astatine the meat of this report.', 'A proposal for an early quota system bequeath constitute At the midway of this report.', 'A proposal for an early quota system testament Be at the plaza of this report.', 'A proposal for an early quota system volition comprise at the midpoint of this report.']\n"
          ]
        }
      ],
      "source": [
        "# Call synonym method for add synonym(s)\n",
        "text = 'A proposal for an early quota system will be at the center of this report.' # Main text\n",
        "sth_keep = ['early quota system'] # Parts of text that should be kept\n",
        "\n",
        "results = []\n",
        "\n",
        "if text.replace(' ', '') != '':\n",
        "    results = add_synonym(text, sth_keep)\n",
        "\n",
        "print('Text: ', text)\n",
        "print('Parts of text that should be kept: ', sth_keep)\n",
        "print('Results: ', results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}